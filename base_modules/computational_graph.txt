Computational graph

The key to parallel programming is determining which steps within a program can be executed in parallel and then,
figuring out how to coordinate them, and one tool to help model how steps in a program relate to each other is
a computational graph.


Task: Unit of Execution or Unit of Work [Nodes/Vertices]
Arrows: indicate progression from one task to the next [Edge]

A task cannot begin executing until all of the tasks with arrows feeding into it have completed.

Consider the steps to make a very simple salad. I'll need to chop some lettuce, chop some tomatoes, mix those chopped
ingredients together, and then finally add salad dressing. Each of those steps represents a task which is a unit of
execution or a unit of work.

Asynchronously: meaning the order in which they happen relative to each other doesn't really matter.
Spawn/Fork:
Sync/Join:

Directed Acyclic Graph or DAG:
Directed because each edge is directed from one node or vertex to another, and acyclic meaning it doesn't have any
loops that cycle back on itself. There are several variations and ways to draw these types of computational graphs,
but their general-purpose is to provide an abstract representation of the program. They help to visualize the
relationship and dependencies between tasks. They can also be used to get a sense of how parallel a program can be.
Every node represents a task or operation and for each one I'll indicate the amount of time it takes to execute.

Work: If we add together the execution times for all of the nodes, that gives me a metric called work which represents
the time it would take to execute all of these tasks on a single processor.

Span: Identify the longest possible path through the graph, following the directed edges from node to node, which is
referred to as the critical path. It represents the longest series of sequential operations through the program. If I
add together the times for all of those nodes along the critical path, I get another metric called span which
indicates the shortest possible execution time if this program was parallelized as much as possible.

The ratio of work to span indicates the ideal parallelism of this program. How much faster can the parallel version
of this program possibly run using multiple processors than the sequential version running on just one processor?
